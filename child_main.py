import json
import random
import requests
import uuid
import os
from dotenv import load_dotenv

# ç§»é™¤ä¸å¿…è¦çš„å¯¼å…¥ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ç›´æ¥çš„ HTTP è¯·æ±‚
# from api_llm_caller import call_llm_placeholder
# from my_prompts import GENERATE_CHILD_RESPONSE_PROMPT, EVALUATE_CHILD_RESPONSE_PROMPT

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# --- Strapi é…ç½® ---
STRAPI_BASE_URL = "http://127.0.0.1:1337"
STRAPI_API_PERSONALITY_PATH = "personality-traits" # ç¡®ä¿ä¸ Strapi Collection Type API ID ä¸€è‡´
STRAPI_API_SCENARIO_PATH = "dialogue-scenarios"

class ChildInteractionSimulator:
    def __init__(self, personality_data, trait_expression_data, scenario_instance_data, daily_challenges_data):
        # 1. åŸºç¡€éªŒè¯ï¼šç¡®ä¿ä¼ å…¥çš„æ•°æ®åˆ—è¡¨å­˜åœ¨ï¼ˆå¯ä»¥ä¸ºç©ºï¼Œä½†ä¸èƒ½ä¸ºNoneï¼‰
        if personality_data is None or trait_expression_data is None or scenario_instance_data is None or daily_challenges_data is None:
            raise ValueError("åˆå§‹åŒ–ChildInteractionSimulatoréœ€è¦å®Œæ•´çš„äººæ ¼ã€ç‰¹è´¨è¡¨ç°ã€æƒ…å¢ƒå®ä¾‹å’Œæ—¥å¸¸æŒ‘æˆ˜æ•°æ®ã€‚")

        # 2. å°†ä» app.py æ¥æ”¶åˆ°çš„æ‰€æœ‰æ•°æ®åˆ—è¡¨å­˜å‚¨ä¸ºå®ä¾‹å˜é‡
        self.personalities = personality_data or []
        self.trait_expressions = trait_expression_data or []
        self.scenario_instances = scenario_instance_data or []
        self.daily_challenges = daily_challenges_data or []
        
        # 3. æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        print(f"ChildInteractionSimulator initialized with:")
        print(f"  - Personalities: {len(self.personalities)} items")
        print(f"  - Trait expressions: {len(self.trait_expressions)} items")
        print(f"  - Scenario instances: {len(self.scenario_instances)} items")
        print(f"  - Daily challenges: {len(self.daily_challenges)} items")

        # --- ã€å…³é”®ä¿®æ”¹ã€‘ç§»é™¤æ‰€æœ‰è¯•å›¾åœ¨ __init__ ä¸­ç›´æ¥ä»åˆ—è¡¨æå–å•ä¸ªå±æ€§çš„ä»£ç  ---
        # æ‚¨ä¹‹å‰å¯èƒ½æœ‰çš„ç±»ä¼¼å¦‚ä¸‹çš„è¡Œï¼Œéƒ½åº”è¯¥è¢«åˆ é™¤æˆ–æ³¨é‡Šæ‰ï¼š
        # self.personality_name = self.personality_data.get('attributes', {}).get('name', 'æœªçŸ¥äººæ ¼') # è¿™æ˜¯ä¸Šæ¬¡çš„é”™è¯¯
        # self.personality_desc = self.personality_data.get('attributes', {}).get('description', '') # è¿™æ˜¯å½“å‰é”™è¯¯çš„æ¥æº
        # self.key_characteristic = self.personality_data.get('attributes', {}).get('keycharacteristic', [])
        # self.core_need = self.personality_data.get('attributes', {}).get('core_need', '')
        # self.initial_dialogue_starter = self.scenario_instance_data.get('attributes', {}).get('initial_dialogue_starter', '')
        # self.default_trait_expression = self.trait_expression_data.get('attributes', {}).get('default_expression', '')

        # ã€åœ¨è¿™é‡Œåˆå§‹åŒ–æ‚¨çš„ LLM æ¨¡å‹ï¼Œå¦‚æœå®ƒéœ€è¦é€šç”¨æ•°æ®ã€‘
        # ä¾‹å¦‚ï¼šself.llm_model = YourActualLLMModel(config_params)
        # ç¡®ä¿æ‚¨å·²ç»å¯¼å…¥äº† LLM ç›¸å…³çš„åº“
        # self.llm_model = MockLLM() # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œæ‚¨éœ€è¦æ›¿æ¢ä¸ºæ‚¨çš„å®é™…LLMåˆå§‹åŒ–

        print("ChildInteractionSimulator initialized with all data lists.")

    def clean_markdown_content(self, content):
        """
        æ¸…ç† AI æ¨¡å‹è¾“å‡ºä¸­çš„ Markdown ä»£ç å—æ ‡è®°
        
        Args:
            content (str): åŒ…å« Markdown æ ‡è®°çš„å†…å®¹
            
        Returns:
            str: æ¸…ç†åçš„å†…å®¹
        """
        if not content:
            return content
            
        # ç§»é™¤ ```json å’Œ ``` æ ‡è®°
        content = content.strip()
        
        # ç§»é™¤å¼€å¤´çš„ ```json æˆ– ``` æ ‡è®°
        if content.startswith('```json'):
            content = content[7:].strip()
        elif content.startswith('```'):
            content = content[3:].strip()
            
        # ç§»é™¤ç»“å°¾çš„ ``` æ ‡è®°
        if content.endswith('```'):
            content = content[:-3].strip()
            
        # ç§»é™¤å¯èƒ½çš„è¯­è¨€æ ‡è¯†ç¬¦ï¼ˆå¦‚ ```python, ```javascript ç­‰ï¼‰
        lines = content.split('\n')
        if lines and lines[0].startswith('```'):
            lines = lines[1:]
        if lines and lines[-1].startswith('```'):
            lines = lines[:-1]
            
        return '\n'.join(lines).strip()

    def call_qwen_api(self, prompt, model="qwen-turbo", temperature=0.7, max_tokens=1000):
        """
        è°ƒç”¨é˜¿é‡Œäº‘åƒé—® API
        
        Args:
            prompt (str): è¾“å…¥æç¤º
            model (str): æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º qwen-turbo
            temperature (float): æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            max_tokens (int): æœ€å¤§è¾“å‡º token æ•°
            
        Returns:
            str: API å“åº”å†…å®¹
        """
        api_key = os.getenv('ALIYUN_DASHSCOPE_API_KEY')
        if not api_key:
            raise ValueError("æœªè®¾ç½® ALIYUN_DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        
        # é˜¿é‡Œäº‘ DashScope API ç«¯ç‚¹
        url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "input": {
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            },
            "parameters": {
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": 0.8,
                "result_format": "message"
            }
        }
        
        try:
            print(f"DEBUG: æ­£åœ¨è°ƒç”¨åƒé—® APIï¼Œæ¨¡å‹: {model}")
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            print(f"DEBUG: åƒé—® API å“åº”: {result}")
            
            # æå–å“åº”å†…å®¹
            if 'output' in result and 'choices' in result['output']:
                content = result['output']['choices'][0]['message']['content']
                # æ¸…ç† Markdown æ ‡è®°
                cleaned_content = self.clean_markdown_content(content)
                print(f"DEBUG: åŸå§‹ API å“åº”: {content}")
                print(f"DEBUG: æ¸…ç†åçš„å†…å®¹: {cleaned_content}")
                return cleaned_content
            else:
                raise ValueError(f"åƒé—® API å“åº”æ ¼å¼å¼‚å¸¸: {result}")
                
        except requests.exceptions.RequestException as e:
            print(f"ERROR: è°ƒç”¨åƒé—® API å¤±è´¥: {e}")
            raise
        except Exception as e:
            print(f"ERROR: å¤„ç†åƒé—® API å“åº”å¤±è´¥: {e}")
            raise

    def build_child_response_prompt(self, parent_utterance, personality_data, challenge_data):
        """
        æ„å»ºç”Ÿæˆå­©å­å›åº”çš„æç¤º
        
        Args:
            parent_utterance (str): çˆ¶çº§è¾“å…¥
            personality_data (dict): äººæ ¼æ•°æ®
            challenge_data (dict): æŒ‘æˆ˜æ•°æ®
            
        Returns:
            str: æ„å»ºçš„æç¤º
        """
        personality_name = personality_data.get('name', 'æœªçŸ¥äººæ ¼')
        personality_desc = personality_data.get('description', 'æ— æè¿°')
        key_characteristics = personality_data.get('keycharacteristic', [])
        core_need = personality_data.get('core_need_description', 'æ— ')
        
        challenge_name = challenge_data.get('name', 'æœªçŸ¥æŒ‘æˆ˜')
        challenge_desc = challenge_data.get('description', 'æ— æè¿°')
        
        # æ„å»ºç‰¹å¾å­—ç¬¦ä¸²
        characteristics_str = "ã€".join(key_characteristics) if key_characteristics else "æ— ç‰¹æ®Šç‰¹å¾"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ª{personality_name}çš„å­©å­ï¼Œæ­£åœ¨ç»å†{challenge_name}è¿™ä¸ªæŒ‘æˆ˜ã€‚

äººæ ¼ç‰¹å¾ï¼š
- äººæ ¼åç§°ï¼š{personality_name}
- äººæ ¼æè¿°ï¼š{personality_desc}
- å…³é”®ç‰¹å¾ï¼š{characteristics_str}
- æ ¸å¿ƒéœ€æ±‚ï¼š{core_need}

å½“å‰æŒ‘æˆ˜ï¼š
- æŒ‘æˆ˜åç§°ï¼š{challenge_name}
- æŒ‘æˆ˜æè¿°ï¼š{challenge_desc}

ç°åœ¨ï¼Œä½ çš„çˆ¶æ¯å¯¹ä½ è¯´ï¼š"{parent_utterance}"

è¯·ä»¥{personality_name}çš„äººæ ¼ç‰¹å¾ï¼Œåœ¨{challenge_name}çš„æŒ‘æˆ˜ä¸‹ï¼Œç»™å‡ºä¸€ä¸ªè‡ªç„¶ã€çœŸå®çš„å›åº”ã€‚å›åº”åº”è¯¥ï¼š
1. ç¬¦åˆä½ çš„äººæ ¼ç‰¹å¾
2. åæ˜ ä½ çš„æ ¸å¿ƒéœ€æ±‚
3. åœ¨ç»™å®šæŒ‘æˆ˜ä¸‹æ˜¯åˆç†çš„
4. è¯­è¨€è‡ªç„¶ï¼ŒåƒçœŸå®çš„å­©å­è¯´è¯

è¯·ç›´æ¥ç»™å‡ºå›åº”ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å‰ç¼€ï¼š"""

        return prompt

    def build_evaluation_prompt(self, parent_utterance, child_response, personality_data, challenge_data):
        """
        æ„å»ºè¯„ä¼°çˆ¶çº§è¾“å…¥çš„æç¤º
        
        Args:
            parent_utterance (str): çˆ¶çº§è¾“å…¥
            child_response (str): å­©å­å›åº”
            personality_data (dict): äººæ ¼æ•°æ®
            challenge_data (dict): æŒ‘æˆ˜æ•°æ®
            
        Returns:
            str: æ„å»ºçš„æç¤º
        """
        personality_name = personality_data.get('name', 'æœªçŸ¥äººæ ¼')
        personality_desc = personality_data.get('description', 'æ— æè¿°')
        key_characteristics = personality_data.get('keycharacteristic', [])
        core_need = personality_data.get('core_need_description', 'æ— ')
        
        challenge_name = challenge_data.get('name', 'æœªçŸ¥æŒ‘æˆ˜')
        challenge_desc = challenge_data.get('description', 'æ— æè¿°')
        
        characteristics_str = "ã€".join(key_characteristics) if key_characteristics else "æ— ç‰¹æ®Šç‰¹å¾"
        
        prompt = f"""è¯·ä¸¥æ ¼è¯„ä¼°ä»¥ä¸‹äº²å­æ²Ÿé€šçš„è´¨é‡ã€‚è¯„åˆ†æ ‡å‡†å¦‚ä¸‹ï¼š

ã€è¯„åˆ†æ ‡å‡†ã€‘
- 90-100åˆ†ï¼šå®Œç¾æ²Ÿé€šï¼Œå®Œå…¨ç†è§£å­©å­éœ€æ±‚ï¼Œè¡¨è¾¾æ°å½“ï¼Œç»™äºˆå……åˆ†æ”¯æŒ
- 80-89åˆ†ï¼šè‰¯å¥½æ²Ÿé€šï¼ŒåŸºæœ¬ç†è§£å­©å­éœ€æ±‚ï¼Œè¡¨è¾¾è¾ƒæ°å½“
- 70-79åˆ†ï¼šä¸€èˆ¬æ²Ÿé€šï¼Œéƒ¨åˆ†ç†è§£å­©å­éœ€æ±‚ï¼Œè¡¨è¾¾æœ‰å¾…æ”¹è¿›
- 60-69åˆ†ï¼šè¾ƒå·®æ²Ÿé€šï¼Œç¼ºä¹å¯¹å­©å­éœ€æ±‚çš„ç†è§£ï¼Œè¡¨è¾¾ä¸å½“
- 50-59åˆ†ï¼šå·®æ²Ÿé€šï¼Œå¿½è§†å­©å­éœ€æ±‚ï¼Œè¡¨è¾¾ä¼¤å®³æ€§
- 40-49åˆ†ï¼šå¾ˆå·®æ²Ÿé€šï¼Œå®Œå…¨å¿½è§†å­©å­éœ€æ±‚ï¼Œè¡¨è¾¾æå…·ä¼¤å®³æ€§
- 30-39åˆ†ï¼šæå·®æ²Ÿé€šï¼Œå¯¹å­©å­é€ æˆå¿ƒç†ä¼¤å®³

ã€æ‰£åˆ†é¡¹ã€‘
- æŒ‡è´£ã€æ‰¹è¯„ï¼š-15åˆ†
- å¿½è§†å­©å­äººæ ¼ç‰¹è´¨ï¼š-10åˆ†
- å¿½è§†æ ¸å¿ƒéœ€æ±‚ï¼š-10åˆ†
- å‘½ä»¤å¼è¯­æ°”ï¼š-8åˆ†
- ç¼ºä¹åŒç†å¿ƒï¼š-8åˆ†
- è¿‡åº¦æ§åˆ¶ï¼š-5åˆ†
- æƒ…ç»ªåŒ–è¡¨è¾¾ï¼š-5åˆ†

å­©å­äººæ ¼ä¿¡æ¯ï¼š
- äººæ ¼åç§°ï¼š{personality_name}
- äººæ ¼æè¿°ï¼š{personality_desc}
- å…³é”®ç‰¹å¾ï¼š{characteristics_str}
- æ ¸å¿ƒéœ€æ±‚ï¼š{core_need}

å½“å‰æŒ‘æˆ˜ï¼š
- æŒ‘æˆ˜åç§°ï¼š{challenge_name}
- æŒ‘æˆ˜æè¿°ï¼š{challenge_desc}

å¯¹è¯å†…å®¹ï¼š
- çˆ¶æ¯è¯´ï¼š"{parent_utterance}"
- å­©å­å›åº”ï¼š"{child_response}"

è¯·ä¸¥æ ¼æŒ‰ç…§è¯„åˆ†æ ‡å‡†è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š

{{
    "evaluation_score": 75,
    "reason_analysis": "è¯¦ç»†åˆ†æçˆ¶æ¯å›åº”çš„è´¨é‡ï¼ŒåŒ…æ‹¬æ‰£åˆ†åŸå› å’Œæ”¹è¿›å»ºè®®",
    "parent_input_analysis": {{
        "recognized_trait": "è¯†åˆ«åˆ°çš„äººæ ¼ç‰¹è´¨",
        "recognized_need": "è¯†åˆ«åˆ°çš„æ ¸å¿ƒéœ€æ±‚",
        "communication_style": "æ²Ÿé€šé£æ ¼",
        "positive_aspects": ["ç§¯ææ–¹é¢1", "ç§¯ææ–¹é¢2"],
        "areas_for_improvement": ["éœ€è¦æ”¹è¿›çš„æ–¹é¢1", "éœ€è¦æ”¹è¿›çš„æ–¹é¢2"]
    }},
    "child_desired_response": "å­©å­ç†æƒ³å›åº”çš„ç¤ºä¾‹",
    "child_desired_response_inner_monologue": "å­©å­å†…å¿ƒç‹¬ç™½"
}}

ã€è¯„ä¼°è¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œä¸è¦è¿‡äºæ¸©å’Œ
2. æ˜ç¡®æŒ‡å‡ºçˆ¶æ¯çš„é”™è¯¯å’Œä¸è¶³
3. åˆ†ææ˜¯å¦ç†è§£å­©å­çš„äººæ ¼ç‰¹è´¨å’Œæ ¸å¿ƒéœ€æ±‚
4. è¯„ä¼°æ²Ÿé€šæ–¹å¼æ˜¯å¦æ°å½“
5. æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼š"""

        return prompt

    def simulate_dialogue(self, parent_utterance, selected_personality_name, selected_challenge_name):
        # è¿™ä¸ªæ–¹æ³•æ¥æ”¶åˆ°é€‰å®šçš„äººæ ¼åç§°å’ŒæŒ‘æˆ˜åç§°
        # é¦–å…ˆï¼Œä»å­˜å‚¨çš„åˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„å®Œæ•´æ•°æ®å¯¹è±¡

        current_personality = next(
            (p for p in self.personalities if p.get('name') == selected_personality_name),
            None
        )
        if not current_personality:
            raise ValueError(f"æ¨¡æ‹Ÿå¯¹è¯å¤±è´¥: æ‰¾ä¸åˆ°æŒ‡å®šçš„äººæ ¼ '{selected_personality_name}'ã€‚")

        # ä» daily_challenges ä¸­æŸ¥æ‰¾æŒ‘æˆ˜æ•°æ®
        current_challenge = next(
            (c for c in self.daily_challenges if c.get('name') == selected_challenge_name),
            None
        )
        if not current_challenge:
            raise ValueError(f"æ¨¡æ‹Ÿå¯¹è¯å¤±è´¥: æ‰¾ä¸åˆ°æŒ‡å®šçš„æŒ‘æˆ˜ '{selected_challenge_name}'ã€‚")

        # ç°åœ¨ï¼Œæ‚¨æœ‰äº† `current_personality` å’Œ `current_challenge` è¿™ä¸¤ä¸ªå­—å…¸ï¼Œ
        # å®ƒä»¬åŒ…å«äº†é€‰å®šäººæ ¼å’ŒæŒ‘æˆ˜çš„æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ã€‚
        # æ‚¨å¯ä»¥ä»è¿™é‡Œå®‰å…¨åœ°è®¿é—®å®ƒä»¬çš„å±æ€§ï¼Œä¾‹å¦‚ï¼š
        personality_description = current_personality.get('description', 'æ— æè¿°')
        challenge_name = current_challenge.get('name', 'æ— æŒ‘æˆ˜åç§°')
        # ... ä»¥åŠå…¶ä»–æ‚¨éœ€è¦çš„äººæ ¼æˆ–æŒ‘æˆ˜å±æ€§

        # --- ã€åœ¨è¿™é‡Œé›†æˆæ‚¨çš„ LLM æ¨¡å‹å’Œæ¨¡æ‹Ÿé€»è¾‘ã€‘ ---
        # ä»¥ä¸‹æ˜¯æ¨¡æ‹Ÿè¾“å‡ºçš„å ä½ç¬¦ï¼Œæ‚¨éœ€è¦ç”¨å®é™…çš„ LLM è°ƒç”¨å’Œå¤„ç†é€»è¾‘æ¥æ›¿æ¢å®ƒã€‚
        # è¿™å°†æ˜¯æ‚¨æ ¸å¿ƒæ¨¡æ‹Ÿé€»è¾‘çš„åœ°æ–¹ï¼Œéœ€è¦ç»“åˆ personality, trait_expressions, scenario_instances,
        # ä»¥åŠ parent_utterance å’Œ LLM æ¥ç”Ÿæˆ child_response å’Œè¯„ä¼°ã€‚

        print(f"DEBUG: æ­£åœ¨æ¨¡æ‹Ÿå¯¹è¯ã€‚çˆ¶çº§è¾“å…¥: '{parent_utterance}', é€‰å®šäººæ ¼: '{current_personality.get('name')}', é€‰å®šæŒ‘æˆ˜: '{current_challenge.get('name')}'")
        
        try:
            # 1. æ„å»ºå­©å­å›åº”çš„æç¤º
            child_prompt = self.build_child_response_prompt(parent_utterance, current_personality, current_challenge)
            print(f"DEBUG: å­©å­å›åº”æç¤º: {child_prompt}")
            
            # 2. è°ƒç”¨åƒé—® API ç”Ÿæˆå­©å­å›åº”
            child_response = self.call_qwen_api(child_prompt, temperature=0.8, max_tokens=500)
            print(f"DEBUG: ç”Ÿæˆçš„å­©å­å›åº”: {child_response}")
            
            # 3. æ„å»ºè¯„ä¼°æç¤º
            evaluation_prompt = self.build_evaluation_prompt(parent_utterance, child_response, current_personality, current_challenge)
            print(f"DEBUG: è¯„ä¼°æç¤º: {evaluation_prompt}")
            
            # 4. è°ƒç”¨åƒé—® API è¿›è¡Œè¯„ä¼°
            evaluation_response = self.call_qwen_api(evaluation_prompt, temperature=0.3, max_tokens=800)
            print(f"DEBUG: è¯„ä¼°å“åº”: {evaluation_response}")
            
            # 5. è§£æè¯„ä¼°ç»“æœ
            try:
                evaluation_data = json.loads(evaluation_response)
                result = {
                    "child_response": child_response,
                    "evaluation_score": evaluation_data.get("evaluation_score", 75),
                    "reason_analysis": evaluation_data.get("reason_analysis", "è¯„ä¼°åˆ†æ"),
                    "parent_input_analysis": evaluation_data.get("parent_input_analysis", {
                        "recognized_trait": "æ— ",
                        "recognized_need": "æ— ",
                        "communication_style": "æœªçŸ¥",
                        "positive_aspects": ["æ— "],
                        "areas_for_improvement": ["æ— "]
                    }),
                    "child_desired_response": evaluation_data.get("child_desired_response", "ç†æƒ³å›åº”"),
                    "child_desired_response_inner_monologue": evaluation_data.get("child_desired_response_inner_monologue", "å†…å¿ƒç‹¬ç™½")
                }
                print(f"DEBUG: å†…å¿ƒç‹¬ç™½å­—æ®µå€¼: {result['child_desired_response_inner_monologue']}")
            except json.JSONDecodeError as e:
                print(f"WARNING: æ— æ³•è§£æè¯„ä¼°JSONï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                result = {
                    "child_response": child_response,
                    "evaluation_score": 65,
                    "reason_analysis": "çˆ¶æ¯å›åº”éœ€è¦æ”¹è¿›ï¼Œç¼ºä¹å¯¹å­©å­äººæ ¼ç‰¹è´¨å’Œæ ¸å¿ƒéœ€æ±‚çš„æ·±å…¥ç†è§£",
                    "parent_input_analysis": {
                        "recognized_trait": current_personality.get('keycharacteristic', ['æ— '])[0] if current_personality.get('keycharacteristic') else 'æ— ',
                        "recognized_need": current_personality.get('core_need_description', 'æ— '),
                        "communication_style": "ä¸€èˆ¬è¯¢é—®å¼",
                        "positive_aspects": ["å°è¯•æ²Ÿé€š"],
                        "areas_for_improvement": ["éœ€è¦æ›´å¥½åœ°ç†è§£å­©å­çš„äººæ ¼ç‰¹è´¨", "ç¼ºä¹é’ˆå¯¹æ€§çš„å›åº”", "æ²Ÿé€šæ–¹å¼éœ€è¦æ”¹è¿›"]
                    },
                    "child_desired_response": "ç†æƒ³å›åº”",
                    "child_desired_response_inner_monologue": f"ï¼ˆå†…å¿ƒç‹¬ç™½ï¼‰ä½œä¸º{current_personality.get('name', 'å­©å­')}ï¼Œæˆ‘å¸Œæœ›çˆ¶æ¯èƒ½æ›´å¥½åœ°ç†è§£æˆ‘çš„{current_personality.get('core_need_description', 'éœ€æ±‚')}ã€‚"
                }
            
            return result
            
        except Exception as e:
            print(f"ERROR: è°ƒç”¨åƒé—® API å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”: {e}")
            # å¦‚æœ API è°ƒç”¨å¤±è´¥ï¼Œè¿”å›æ¨¡æ‹Ÿå“åº”
            mock_response = {
                "child_response": f"ï¼ˆå­©å­ä½œä¸º'{current_personality.get('name')}'äººæ ¼ï¼Œåœ¨'{current_challenge.get('name')}'æŒ‘æˆ˜ä¸‹å›åº”ï¼‰æˆ‘å¬åˆ°äº†ä½ çš„è¯ï¼Œæˆ‘éœ€è¦ä¸€ç‚¹æ—¶é—´æ¥æ€è€ƒä¸€ä¸‹ã€‚",
                "evaluation_score": random.randint(50, 75),
                "reason_analysis": "çˆ¶æ¯å›åº”éœ€è¦æ”¹è¿›ï¼Œç¼ºä¹å¯¹å­©å­äººæ ¼ç‰¹è´¨å’Œæ ¸å¿ƒéœ€æ±‚çš„æ·±å…¥ç†è§£ã€‚æ²Ÿé€šæ–¹å¼æœ‰å¾…æå‡ã€‚",
                "parent_input_analysis": {
                    "recognized_trait": current_personality.get('keycharacteristic', ['æ— '])[0] if current_personality.get('keycharacteristic') else 'æ— ',
                    "recognized_need": current_personality.get('core_need_description', 'æ— '),
                    "communication_style": "ä¸€èˆ¬è¯¢é—®å¼ï¼Œç¼ºä¹é’ˆå¯¹æ€§",
                    "positive_aspects": ["å°è¯•æ²Ÿé€š"],
                    "areas_for_improvement": ["éœ€è¦æ›´å¥½åœ°ç†è§£å­©å­çš„äººæ ¼ç‰¹è´¨", "ç¼ºä¹é’ˆå¯¹æ€§çš„å›åº”", "æ²Ÿé€šæ–¹å¼éœ€è¦æ”¹è¿›", "éœ€è¦æ›´æœ‰åŒç†å¿ƒ"]
                },
                "child_desired_response": "ï¼ˆç†æƒ³å›åº”ï¼‰è°¢è°¢ä½ ï¼Œå¦ˆå¦ˆ/çˆ¸çˆ¸ï¼Œç»™æˆ‘ç‚¹æ—¶é—´ï¼Œæˆ‘å¾ˆå¿«å°±ä¼šå‘Šè¯‰ä½ æˆ‘çš„æƒ³æ³•ã€‚",
                "child_desired_response_inner_monologue": f"ï¼ˆå†…å¿ƒç‹¬ç™½ï¼‰ä½œä¸º{current_personality.get('name', 'å­©å­')}ï¼Œæˆ‘å¸Œæœ›çˆ¶æ¯èƒ½æ›´å¥½åœ°ç†è§£æˆ‘çš„{current_personality.get('core_need_description', 'éœ€æ±‚')}ã€‚"
            }
            print(f"DEBUG: æ¨¡æ‹Ÿå“åº”å†…å¿ƒç‹¬ç™½å­—æ®µå€¼: {mock_response['child_desired_response_inner_monologue']}")
            return mock_response

    # æ‚¨å¯èƒ½éœ€è¦æ·»åŠ å…¶ä»–è¾…åŠ©æ–¹æ³•ï¼Œä¾‹å¦‚ _prepare_llm_input å’Œ _parse_llm_output
    # def _prepare_llm_input(self, parent_utterance, personality_data, challenge_data, trait_expressions):
    #     # æ ¹æ®æ•°æ®æ„å»ºç»™LLMçš„æç¤º
    #     pass

    # def _parse_llm_output(self, llm_raw_output):
    #     # è§£æLLMçš„åŸå§‹è¾“å‡ºï¼Œæå–æ‰€éœ€ä¿¡æ¯
    #     pass

    def to_json(self):
        return json.dumps({
            "session_id": self.session_id,
            "dialogue_history": self.dialogue_history,
            "child_personality": self.child_personality,
            "core_need": self.core_need,
            "current_scenario": self.current_scenario,
        })

    @classmethod
    def from_json(cls, json_str):
        data = json.loads(json_str)
        simulator = cls(
            personality_name=data.get("child_personality", {}).get("name", ""),
            scenario_title=data.get("current_scenario", {}).get("name", ""),
            session_id=data.get("session_id")
        )
        simulator.dialogue_history = data.get("dialogue_history", [])
        simulator.child_personality = data.get("child_personality", {})
        simulator.core_need = data.get("core_need", {})
        simulator.current_scenario = data.get("current_scenario", {})
        return simulator

    def initialize_child_and_scenario(self, personality_name, scenario_title):
        print(f"--- å°è¯•åˆå§‹åŒ–ï¼šäººæ ¼åç§°='{personality_name}', æƒ…å¢ƒæ ‡é¢˜='{scenario_title}' ---")
        try:
            # --- äººæ ¼åˆå§‹åŒ– ---
            personality_url = f"{STRAPI_BASE_URL}/api/{STRAPI_API_PERSONALITY_PATH}?filters[name][$eq]={personality_name}"
            print(f"DEBUG: æ­£åœ¨è¯·æ±‚äººæ ¼URL: {personality_url}")
            personality_response = requests.get(personality_url)
            print(f"DEBUG: äººæ ¼è¯·æ±‚çŠ¶æ€ç : {personality_response.status_code}")
            print(f"DEBUG: äººæ ¼è¯·æ±‚å“åº”æ–‡æœ¬: {personality_response.text[:1000]}...")

            personality_response.raise_for_status()
            personality_data = personality_response.json().get('data', [])

            if personality_data:
                self.child_personality = personality_data[0] # ç›´æ¥ä½¿ç”¨è¿™ä¸ªå­—å…¸
                self.core_need = {"description": self.child_personality.get('core_need_description', 'æ— æ ¸å¿ƒéœ€æ±‚')}

                print(f"--- å­©å­äººæ ¼åˆå§‹åŒ–æˆåŠŸ: {self.child_personality.get('name')} ---")
                print(f"DEBUG: å­©å­äººæ ¼è¯¦ç»†æ•°æ®ï¼ˆéƒ¨åˆ†ï¼‰: {json.dumps(self.child_personality, indent=2)[:1000]}...")
                print(f"DEBUG: å­©å­æ ¸å¿ƒéœ€æ±‚: {self.core_need}")
            else:
                print(f"!!! è­¦å‘Š: æœªæ‰¾åˆ°æŒ‡å®šçš„äººæ ¼: '{personality_name}' (Strapiè¿”å›æ•°æ®ä¸ºç©ºæˆ–ä¸å­˜åœ¨) !!!")
                self.child_personality = {"name": "é»˜è®¤å­©å­", "description": "æ— æè¿°"}
                self.core_need = {"description": "æ— æ ¸å¿ƒéœ€æ±‚"}

            # --- æƒ…å¢ƒåˆå§‹åŒ– ---
            scenario_url = f"{STRAPI_BASE_URL}/api/{STRAPI_API_SCENARIO_PATH}?filters[name][$eq]={scenario_title}"
            print(f"DEBUG: æ­£åœ¨è¯·æ±‚æƒ…å¢ƒURL: {scenario_url}")
            scenario_response = requests.get(scenario_url)
            print(f"DEBUG: æƒ…å¢ƒè¯·æ±‚çŠ¶æ€ç : {scenario_response.status_code}")
            print(f"DEBUG: æƒ…å¢ƒè¯·æ±‚å“åº”æ–‡æœ¬: {scenario_response.text[:1000]}...")

            scenario_response.raise_for_status()
            scenario_data = scenario_response.json().get('data', [])

            if scenario_data:
                self.current_scenario = scenario_data[0] # ç›´æ¥ä½¿ç”¨è¿™ä¸ªå­—å…¸
                print(f"--- æƒ…å¢ƒåˆå§‹åŒ–æˆåŠŸ: {self.current_scenario.get('name')} ---")
                print(f"DEBUG: æƒ…å¢ƒè¯¦ç»†æ•°æ®ï¼ˆéƒ¨åˆ†ï¼‰: {json.dumps(self.current_scenario, indent=2)[:1000]}...")
            else:
                print(f"!!! è­¦å‘Š: æœªæ‰¾åˆ°æŒ‡å®šçš„æƒ…å¢ƒ: '{scenario_title}' (Strapiè¿”å›æ•°æ®ä¸ºç©ºæˆ–ä¸å­˜åœ¨) !!!")
                self.current_scenario = {"name": "é»˜è®¤æƒ…å¢ƒ", "description": "æ— æè¿°"}

        except requests.exceptions.ConnectionError as e:
            print(f"!!! é”™è¯¯: æ— æ³•è¿æ¥åˆ°StrapiæœåŠ¡å™¨ï¼è¯·æ£€æŸ¥Strapiæ˜¯å¦è¿è¡Œï¼Œåœ°å€æ˜¯å¦æ­£ç¡®: {e} !!!")
            self.child_personality = {"name": "é»˜è®¤å­©å­", "description": "æ— æè¿°"}
            self.core_need = {"description": "æ— æ ¸å¿ƒéœ€æ±‚"}
            self.current_scenario = {"name": "é»˜è®¤æƒ…å¢ƒ", "description": "æ— æè¿°"}
        except requests.exceptions.HTTPError as e:
            print(f"!!! é”™è¯¯: ä»Strapiè·å–æ•°æ®æ—¶é‡åˆ°HTTPé”™è¯¯: {e.response.status_code} - {e.response.text} !!!")
            self.child_personality = {"name": "é»˜è®¤å­©å­", "description": "æ— æè¿°"}
            self.core_need = {"description": "æ— æ ¸å¿ƒéœ€æ±‚"}
            self.current_scenario = {"name": "é»˜è®¤æƒ…å¢ƒ", "description": "æ— æè¿°"}
        except json.JSONDecodeError as e:
            print(f"!!! é”™è¯¯: è§£æStrapiå“åº”ä¸ºJSONå¤±è´¥: {e} !!!")
            problematic_text = "N/A"
            if 'personality_response' in locals():
                problematic_text = personality_response.text[:1000]
            elif 'scenario_response' in locals():
                problematic_text = scenario_response.text[:1000]
            print(f"DEBUG: å¯¼è‡´JSONè§£æé”™è¯¯çš„æ–‡æœ¬: {problematic_text}...")
            self.child_personality = {"name": "é»˜è®¤å­©å­", "description": "æ— æè¿°"}
            self.core_need = {"description": "æ— æ ¸å¿ƒéœ€æ±‚"}
            self.current_scenario = {"name": "é»˜è®¤æƒ…å¢ƒ", "description": "æ— æè¿°"}
        except Exception as e:
            print(f"!!! å‘ç”ŸæœªçŸ¥é”™è¯¯: {e} !!!")
            self.child_personality = {"name": "é»˜è®¤å­©å­", "description": "æ— æè¿°"}
            self.core_need = {"description": "æ— æ ¸å¿ƒéœ€æ±‚"}
            self.current_scenario = {"name": "é»˜è®¤æƒ…å¢ƒ", "description": "æ— æè¿°"}

    def _build_llm_prompt(self, parent_input):
        # å°†åˆ—è¡¨å½¢å¼çš„ç‰¹å¾æ‹¼æ¥æˆå­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿LLMç†è§£
        personality_key_chars_str = "\n- " + "\n- ".join(self.personality_key_chars) if self.personality_key_chars else "æ— "
        child_behaviors_str = ", ".join(self.child_typical_behavior) if self.child_typical_behavior else "æ— "
        parent_emotions_str = ", ".join(self.parent_typical_emotion) if self.parent_typical_emotion else "æ— "
        root_causes_str = ", ".join(self.potential_root_causes) if self.potential_root_causes else "æ— "

        # é¢„è®¾å›åº”åŒ¹é…
        matched_preset_response = None
        matched_follow_up_hint = None
        parent_input_lower = parent_input.lower()
        for preset_map in self.parent_inputs_map:
            keywords = preset_map.get('parent_keywords', [])
            child_resp_template = preset_map.get('child_response_template')
            follow_up_hint = preset_map.get('follow_up_prompt_hint')
            if any(keyword.lower() in parent_input_lower for keyword in keywords):
                matched_preset_response = child_resp_template
                matched_follow_up_hint = follow_up_hint
                break

        if matched_preset_response:
            prompt_parts = [
                f"ä½ æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå­©å­ï¼Œä½ çš„åå­—æ˜¯ã€{self.personality_name}ã€‘ã€‚",
                f"å®¶é•¿å¯¹ä½ è¯´ï¼šâ€œ{parent_input}â€",
                f"æ ¹æ®é¢„è®¾ï¼Œä½ åº”è¯¥å›å¤ï¼šâ€œ{matched_preset_response}â€",
                f"è¯·ä½ ä»¥ã€{self.personality_name}ã€‘çš„æ€§æ ¼ç‰¹ç‚¹å›å¤å®¶é•¿ï¼Œæ³¨æ„ä¿æŒé¢„è®¾å†…å®¹ä¸å˜ï¼Œä½†å¯ä»¥ç¨å¾®è°ƒæ•´è¯­æ°”ä½¿å…¶æ›´è‡ªç„¶ã€‚",
                f"ä½ çš„æ€§æ ¼ç‰¹ç‚¹ï¼š{self.personality_desc}",
                f"æ ¸å¿ƒéœ€æ±‚ï¼š{self.personality_core_need}",
                f"å…³é”®è¡Œä¸ºæ¨¡å¼ï¼š{personality_key_chars_str}",
                f"å½“å‰å…·ä½“æƒ…å¢ƒåç§°ï¼š{self.scenario_name}",
                f"æƒ…å¢ƒæè¿°ï¼š{self.scenario_desc}",
                f"å­©å­å…¸å‹è¡¨ç°ï¼š{child_behaviors_str}",
                f"å®¶é•¿å¯èƒ½æƒ…ç»ªï¼š{parent_emotions_str}",
                f"å¯èƒ½æ ¹æœ¬åŸå› ï¼š{root_causes_str}",
            ]
            if matched_follow_up_hint:
                prompt_parts.append(f"è¯·ç‰¹åˆ«æ³¨æ„åç»­å¯¹è¯çš„å¾®è°ƒæç¤ºï¼š{matched_follow_up_hint}")
            return "\n".join(prompt_parts)
        else:
            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå­©å­ã€‚
            ä½ çš„æ€§æ ¼ç‰¹å¾æ˜¯ï¼š{self.personality_desc}
            ä½ çš„æ ¸å¿ƒéœ€æ±‚æ˜¯ï¼š{self.personality_core_need}
            ä½ çš„å…³é”®è¡Œä¸ºæ¨¡å¼åŒ…æ‹¬ï¼š
            {personality_key_chars_str}

            å½“å‰æƒ…å¢ƒæ˜¯ï¼šâ€œ{self.scenario_name}â€
            æƒ…å¢ƒæè¿°ï¼š{self.scenario_desc}
            åœ¨è¿™ä¸ªæƒ…å¢ƒä¸‹ï¼Œå­©å­é€šå¸¸çš„è¡¨ç°æ˜¯ï¼š{child_behaviors_str}
            å®¶é•¿æ­¤åˆ»å¯èƒ½æ„Ÿåˆ°ï¼š{parent_emotions_str}
            å¯èƒ½çš„æ ¹æœ¬åŸå› åŒ…æ‹¬ï¼š{root_causes_str}

            è¯·ä½ ä½œä¸ºã€{self.personality_name}ã€‘è¿™ä¸ªå­©å­ï¼Œç»“åˆä½ çš„æ€§æ ¼ç‰¹å¾ã€æ ¸å¿ƒéœ€æ±‚å’Œå½“å‰æƒ…å¢ƒçš„è¯¦ç»†ä¿¡æ¯ï¼Œä»¥åŠä»¥ä¸‹é€šç”¨æŒ‡å¯¼ï¼Œç»™å‡ºè‡ªç„¶ã€çœŸå®çš„å›å¤ã€‚å›å¤è¦ç¬¦åˆå­©å­çš„å¹´é¾„ç‰¹ç‚¹å’Œæƒ…ç»ªçŠ¶æ€ã€‚
            
            é€šç”¨å›å¤æŒ‡å¯¼ï¼š{self.general_response_guidance}

            å®¶é•¿å¯¹ä½ è¯´ï¼šâ€œ{parent_input}â€

            ä½ çš„å›å¤ï¼š
            """
            return prompt

    def _call_llm(self, prompt_type: str, prompt_content: str):
        return call_llm_placeholder(prompt_type, prompt_content)

    def _get_formatted_dialogue_history(self) -> str:
        if not self.dialogue_history:
            return "æ— "
        return "\n".join([f"{'å®¶é•¿' if entry['role']=='parent' else 'å­©å­'}: {entry['content']}" for entry in self.dialogue_history])

    # åˆ é™¤ _generate_evaluation_prompt æ–¹æ³•ï¼Œæ— éœ€ä¿ç•™ä»»ä½•å†…å®¹

    def run_simulation(self):
        print("æ¬¢è¿æ¥åˆ°æ¨¡æ‹Ÿå„¿ç«¥å¯¹è¯æ¨¡æ‹Ÿå™¨ï¼\n")
        print("äººæ ¼ç”»åƒï¼š\n", self.child_personality.strip())
        print("åœºæ™¯æè¿°ï¼š\n", self.current_scenario.strip())
        print("æ ¸å¿ƒéœ€æ±‚ï¼š\n", self.core_need.strip())
        print("\nè¯·è¾“å…¥æ‚¨å¯¹å­©å­è¯´çš„è¯ï¼ˆè¾“å…¥ 'é€€å‡º' å¯ç»“æŸå¯¹è¯ï¼‰")

        while True:
            parent_utterance = input("\næ‚¨å¯¹å­©å­è¯´ï¼š")
            if parent_utterance.lower() == "é€€å‡º":
                print("æ¨¡æ‹Ÿå¯¹è¯ç»“æŸã€‚")
                break

            # æ­¥éª¤ 1ï¼šç”Ÿæˆå­©å­å›åº”
            prompt = GENERATE_CHILD_RESPONSE_PROMPT.format(
                child_personality_profile=self.child_personality,
                scenario_description=self.current_scenario,
                dialogue_history=self._get_formatted_dialogue_history(),
                parent_utterance=parent_utterance
            )
            child_response = self._call_llm("CHILD_RESPONSE", prompt)
            if not child_response:
                print("âš ï¸ æ— æ³•ç”Ÿæˆå­©å­å›åº”ã€‚")
                continue
            print(f"\nå­©å­å›åº”ï¼š{child_response}")
            self.dialogue_history += [
                {"role": "parent", "content": parent_utterance},
                {"role": "child", "content": child_response}
            ]

            # æ­¥éª¤ 2ï¼šç”Ÿæˆå›åº”è¯„ä»·
            eval_prompt = EVALUATE_CHILD_RESPONSE_PROMPT.format(
                child_personality_profile=self.child_personality,
                scenario_description=self.current_scenario,
                parent_utterance=parent_utterance,
                child_response=child_response
            )
            eval_json_str = self._call_llm("EVALUATION", eval_prompt)
            if not eval_json_str:
                print("âš ï¸ æ— æ³•ç”Ÿæˆå›åº”è¯„ä»·ã€‚")
                continue

            try:
                evaluation = json.loads(eval_json_str)
                print("\n--- å›åº”è¯„ä»· ---")
                print(f"ç»¼åˆè¯„ä»·ï¼š{evaluation.get('Evaluation')}")
                print(f"åŸå› åˆ†æï¼š{evaluation.get('ReasonAnalysis')}")

                if evaluation.get("Evaluation", "").upper() != "A":
                    self.non_a_eval_count += 1
                    if self.non_a_eval_count >= 3:
                        print("\nğŸ’¡ è¿ç»­ä¸‰è½®éAå›åº”ï¼Œå­©å­å¿ƒå£°å¦‚ä¸‹ï¼š")
                        print(f"ç†æƒ³å›åº”ï¼š{evaluation.get('ChildDesiredResponse')}")
                        print(f"å†…å¿ƒç‹¬ç™½ï¼š{evaluation.get('ChildDesiredResponseInnerMonologue')}")
                        self.non_a_eval_count = 0
                else:
                    self.non_a_eval_count = 0

            except json.JSONDecodeError:
                print("âš ï¸ è¿”å›æ•°æ®ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼š", eval_json_str)

    def get_child_response(self, parent_input):
        print(f"DEBUG (child_main): Parent input received: {parent_input}")
        prompt = self._build_llm_prompt(parent_input)
        print(f"DEBUG (child_main): LLM Prompt:\n{prompt}")
        try:
            if "æ ¹æ®é¢„è®¾ï¼Œä½ åº”è¯¥å›å¤ï¼š" in prompt:
                start_idx = prompt.find("æ ¹æ®é¢„è®¾ï¼Œä½ åº”è¯¥å›å¤ï¼š") + len("æ ¹æ®é¢„è®¾ï¼Œä½ åº”è¯¥å›å¤ï¼š") + 1
                end_idx = prompt.find("â€", start_idx)
                if start_idx != -1 and end_idx != -1:
                    child_response = prompt[start_idx:end_idx] + "ï¼ˆé¢„è®¾å›å¤ï¼‰"
                else:
                    child_response = "ï¼ˆæœªèƒ½æå–é¢„è®¾å›å¤ï¼Œè¯·æ£€æŸ¥Promptï¼‰"
            else:
                child_response = "ï¼ˆæœªè§¦å‘é¢„è®¾ï¼ŒLLMå°†è‡ªç”±å›å¤ï¼‰"
            print(f"DEBUG (child_main): Child response: {child_response}")
            return child_response
        except Exception as e:
            print(f"ERROR (child_main): è°ƒç”¨LLMå¤±è´¥: {e}")
            return f"å­©å­æš‚æ—¶æ— æ³•å›åº”ï¼Œè¯·ç¨åå†è¯•ã€‚ï¼ˆLLMé”™è¯¯ï¼š{e}ï¼‰"

def get_all_evaluation_rules_from_strapi():
    """
    ä» Strapi æ‹‰å–æ‰€æœ‰è¯„ä¼°è§„åˆ™ï¼Œè¿”å›è§„åˆ™åˆ—è¡¨ã€‚
    """
    import requests
    STRAPI_BASE_URL = "http://localhost:1337"
    STRAPI_API_PATH = "responses"
    try:
        response = requests.get(f"{STRAPI_BASE_URL}/api/{STRAPI_API_PATH}?populate=*")
        response.raise_for_status()
        data = response.json()
        rules = []
        for item in data.get('data', []):
            attrs = item.get('attributes', {})
            # è§£æ parentKeywords å­—æ®µä¸ºåˆ—è¡¨
            if 'parentKeywords' in attrs and isinstance(attrs['parentKeywords'], str):
                import json
                try:
                    attrs['parentKeywords'] = json.loads(attrs['parentKeywords'])
                except Exception:
                    attrs['parentKeywords'] = []
            rules.append(attrs)
        return rules
    except Exception as e:
        print(f"[get_all_evaluation_rules_from_strapi] æ‹‰å–è¯„ä¼°è§„åˆ™å¤±è´¥: {e}")
        return []

# ç¨‹åºå…¥å£
# if __name__ == "__main__":
#     try:
#         simulator = ChildInteractionSimulator(
#             personality_name="æ…¢èƒ½é‡å­©å­",
#             scenario_title="æ²‰æµ¸åœ¨è‡ªå·±ä¸–ç•Œ"
#         )
#         simulator.run_simulation()
#     except Exception as e:
#         print(f"\nâŒ å¯åŠ¨æ¨¡æ‹Ÿå™¨å¤±è´¥ï¼š{e}")

